{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of data ingestion code\n",
    "\n",
    "Note the code in this file is not used directly in the end solution, but large sections are copied into the .py files in the /src folder.\n",
    "\n",
    "I think Notebooks are a good way to prototype and iterate on code, particularly where it involves data (so you can visualise what's going on and prevent headaches down the line) or processes you're not completely familiar with (so you can try things rapidly until they work). This is also a good place to include extra comments along the way, which may be covered in a blog post or simply used by someone who wants to understand the code better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will get a 403 forbidden error unless we look like a browser\n",
    "# to get an appropriate user-agent value:\n",
    "# - Open Google Chrome and go to the website you're interested in (in your case, http://www.bom.gov.au/nsw/forecasts/sydney.shtml).\n",
    "# - Press F12 or right-click on the page and select Inspect to open the Developer Tools.\n",
    "# - Go to the Network tab.\n",
    "# - Reload the page (you can press F5 or click the reload button in the browser).\n",
    "# - In the Network tab, look for the first request that is made (usually listed at the top, with the name of the page you're visiting, e.g., sydney.shtml).\n",
    "# - Click on that request to view its details.\n",
    "# - On the right, you should see a Headers tab. Under the Request Headers section, look for the User-Agent value.\n",
    "# - Copy that User-Agent string and use it in your Python code.\n",
    "\n",
    "def get_page_source(url):\n",
    "    '''returns page source from url'''\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch page: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sydney Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.bom.gov.au/nsw/forecasts/sydney.shtml\"\n",
    "src = get_page_source(url)\n",
    "soup = BeautifulSoup(src, 'html.parser') # recommended to include html.parser here to ensure consistent cross-platform results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to have an initial look at the html code\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast for the rest of Wednesday\n",
      "Thursday 20 March\n",
      "Friday 21 March\n",
      "[['Forecast for the rest of Wednesday', 0.05, 0, 0], ['Thursday 20 March', 0.1, 0, 0], ['Friday 21 March', 0.5, 0, 3]]\n"
     ]
    }
   ],
   "source": [
    "sections = soup.find_all(class_=\"day\", limit=3) # limit=1 # for testing\n",
    "#print([section.text for section in sections])\n",
    "\n",
    "results = []\n",
    "for section in sections:\n",
    "    #print(section.prettify())\n",
    "    date = section.find('h2').text.strip()\n",
    "    print(date)\n",
    "    \n",
    "    rain_section = section.find_next('dd', class_=\"rain\")\n",
    "    # print(rain_section) # while testing\n",
    "    # [<dd class=\"rain\">Chance of any rain: <em class=\"pop\">5%\n",
    "    # \t\t\t\t\t<img alt=\"\" height=\"10\" src=\"/images/ui/weather/rain_5.gif\" width=\"69\"/></em></dd>]\n",
    "    # [<dd class=\"rain\">Chance of any rain: <em class=\"pop\">10%\n",
    "    # \t\t\t\t\t<img alt=\"\" height=\"10\" src=\"/images/ui/weather/rain_10.gif\" width=\"69\"/></em></dd>]\n",
    "    # [<dd class=\"rain\">Possible rainfall: <em class=\"rain\">0 to 3 mm</em></dd>, <dd class=\"rain\">Chance of any rain: <em class=\"pop\">50%\n",
    "    # \t\t\t\t\t<img alt=\"\" height=\"10\" src=\"/images/ui/weather/rain_50.gif\" width=\"69\"/></em></dd>]\n",
    "    # Note that when rain chance exceeds a threshold % the layout is different\n",
    "\n",
    "    rain_mm_low = 0\n",
    "    rain_mm_high = 0\n",
    "    if \"Possible rainfall\" in rain_section.text:\n",
    "        rain_mm = rain_section.find_next('em', class_=\"rain\").text.strip()\n",
    "        match = re.search(r\"(\\d+)\\s*to\\s*(\\d+)\", rain_mm)\n",
    "        if match:\n",
    "            rain_mm_low = int(match.group(1))\n",
    "            rain_mm_high = int(match.group(2))\n",
    "\n",
    "    rain_chance = rain_section.find_next('em', class_=\"pop\").text.strip()\n",
    "    rain_chance = float(rain_chance.strip('%')) / 100\n",
    "\n",
    "    # print('rain_mm_low', rain_mm_low) # while testing\n",
    "    # print('rain_mm_high', rain_mm_high)\n",
    "    # print('rain_chance', rain_chance)\n",
    "\n",
    "    results.append([date, rain_chance, rain_mm_low, rain_mm_high])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for script\n",
    "\n",
    "This will be placed in src and will be called from the database.py and/or data_ingestion.py so should return the data in an array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('19/03/25', '19/03/25')\n",
      "('19/03/25', '21/03/25')\n",
      "('19/03/25', '19/03/25')\n",
      "('19/03/25', '01/01/26')\n"
     ]
    }
   ],
   "source": [
    "def convert_to_datetime(date_str, current_date=None):\n",
    "    '''Converts string from html (e.g. 'Friday 21 March') into datetime (e.g. 21/3/25)\n",
    "    \n",
    "    Keyword args:\n",
    "    current_date -- used for testing the function, defaults to today's date\n",
    "\n",
    "    Returns:\n",
    "    date_forecast_was_made, date_forecast_applies_to -- both in d/m/y string format\n",
    "    '''\n",
    "\n",
    "    if not current_date:\n",
    "        current_date = datetime.today().date()\n",
    "\n",
    "    # forecast for the remainder of the day on which the forecast is made\n",
    "    if \"Forecast\" in date_str:\n",
    "        forecast_date = current_date\n",
    "\n",
    "    else:    \n",
    "        month_day = date_str.split(' ', 1)[1] # remove the weekday portion\n",
    "        current_year = current_date.year\n",
    "\n",
    "        forecast_date = datetime.strptime(f\"{month_day} {current_year}\", \"%d %B %Y\").date() # read in as d mmm y\n",
    "        if forecast_date < current_date:\n",
    "            forecast_date = forecast_date.replace(year=current_year + 1)\n",
    "\n",
    "    # format as d/m/y\n",
    "    return current_date.strftime('%d/%m/%y'), forecast_date.strftime('%d/%m/%y')\n",
    "\n",
    "print(convert_to_datetime('Friday 19 March', datetime.today().date()))\n",
    "print(convert_to_datetime('Friday 21 March', datetime.today().date()))\n",
    "print(convert_to_datetime('Forecast for the rest of today', datetime.today().date())) # check it reads the forecast row correctly\n",
    "print(convert_to_datetime('Friday 1 January', datetime.today().date())) # check it reads dates at the start of next year correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['19/03/25', '19/03/25', 0.05, 0, 0], ['19/03/25', '20/03/25', 0.1, 0, 0], ['19/03/25', '21/03/25', 0.5, 0, 3], ['19/03/25', '22/03/25', 0.4, 0, 1], ['19/03/25', '23/03/25', 0.6, 0, 5], ['19/03/25', '24/03/25', 0.5, 0, 2], ['19/03/25', '25/03/25', 0.5, 0, 5]]\n"
     ]
    }
   ],
   "source": [
    "def forecast_data(soup):\n",
    "    '''Extract rainfall chance and amounts from the Beautiful Soup class'''\n",
    "\n",
    "    sections = soup.find_all(class_=\"day\")\n",
    "    results = []\n",
    "    for section in sections:\n",
    "\n",
    "        # extract the date (which is implied by the current date and this being a forecast for the coming week, includes rest of today)\n",
    "        date_forecast_applies_to = section.find('h2').text.strip()\n",
    "        date_forecast_was_made, date_forecast_applies_to = convert_to_datetime(date_forecast_applies_to)\n",
    "\n",
    "        rain_section = section.find_next('dd', class_=\"rain\")\n",
    "        rain_mm_low = 0\n",
    "        rain_mm_high = 0\n",
    "        if \"Possible rainfall\" in rain_section.text: # rainfall mm is only shown when rainfall chance exceeds some threshold\n",
    "            rain_mm = rain_section.find_next('em', class_=\"rain\").text.strip()\n",
    "            match = re.search(r\"(\\d+)\\s*to\\s*(\\d+)\", rain_mm) # convert 0 to 3 mm into values 0 and 3 using regular expressions\n",
    "            if match:\n",
    "                rain_mm_low = int(match.group(1))\n",
    "                rain_mm_high = int(match.group(2))\n",
    "\n",
    "        rain_chance = rain_section.find_next('em', class_=\"pop\").text.strip()\n",
    "        rain_chance = float(rain_chance.strip('%')) / 100 # convert from text % to float now (might be easier than doing so later on)\n",
    "\n",
    "        results.append([date_forecast_was_made, date_forecast_applies_to, rain_chance, rain_mm_low, rain_mm_high])\n",
    "\n",
    "    return results\n",
    "\n",
    "forecast_data_raw = forecast_data(soup=soup)\n",
    "print(forecast_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  date_forecast_was_made date_forecast_applies_to  rain_chance  rain_mm_low  \\\n",
      "0             2025-03-19               2025-03-19         0.05            0   \n",
      "1             2025-03-19               2025-03-20         0.10            0   \n",
      "2             2025-03-19               2025-03-21         0.50            0   \n",
      "3             2025-03-19               2025-03-22         0.40            0   \n",
      "4             2025-03-19               2025-03-23         0.60            0   \n",
      "5             2025-03-19               2025-03-24         0.50            0   \n",
      "6             2025-03-19               2025-03-25         0.50            0   \n",
      "\n",
      "   rain_mm_high  \n",
      "0             0  \n",
      "1             0  \n",
      "2             3  \n",
      "3             1  \n",
      "4             5  \n",
      "5             2  \n",
      "6             5  \n"
     ]
    }
   ],
   "source": [
    "# convert data to dataframe for ease of filtering etc\n",
    "df = pd.DataFrame(forecast_data_raw, columns=['date_forecast_was_made', 'date_forecast_applies_to', 'rain_chance', 'rain_mm_low', 'rain_mm_high'])\n",
    "df['date_forecast_was_made'] = pd.to_datetime(df['date_forecast_was_made'], format='%d/%m/%y')\n",
    "df['date_forecast_applies_to'] = pd.to_datetime(df['date_forecast_applies_to'], format='%d/%m/%y')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sydney Historical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stn_num = 66037 # Sydney airport\n",
    "url = f\"http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=136&p_display_type=dailyDataFile&p_stn_num={p_stn_num}\"\n",
    "src = get_page_source(url)\n",
    "soup = BeautifulSoup(src, 'html.parser') # recommended to include html.parser here to ensure consistent cross-platform results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [],
   "source": [
    "<table class=\"climatedata tdtooltip\" id=\"dataTable\" summary=\"Daily data, with a column for each month. After the table headings, the first row contains links to graphs of the data.\">\n",
    "        <thead>\n",
    "         <tr>\n",
    "          <th scope=\"col\">\n",
    "           2025\n",
    "          </th>\n",
    "...\n",
    "        <tbody>\n",
    "         <tr class=\"graphcell\">\n",
    "          <th scope=\"row\">\n",
    "           Graph\n",
    "          </th>\n",
    "...\n",
    "         <tr>\n",
    "          <th scope=\"row\">\n",
    "           1st\n",
    "          </th>\n",
    "          <td class=\"no-qc\">\n",
    "           0\n",
    "          </td>\n",
    "          <td class=\"no-qc\">\n",
    "           0\n",
    "          </td>\n",
    "          <td class=\"no-qc\">\n",
    "           0\n",
    "          </td>\n",
    "          <td>\n",
    "         </tr>\n",
    "...\n",
    "         <tr>\n",
    "          <th scope=\"row\">\n",
    "           3rd\n",
    "          </th>\n",
    "          <td class=\"no-qc\">\n",
    "           4.8\n",
    "          </td>\n",
    "          <td class=\"no-qc\">\n",
    "           0\n",
    "          </td>\n",
    "          <td class=\"no-qc\">\n",
    "           0\n",
    "          </td>\n",
    "          <td>\n",
    "          </td>\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2025\n",
      "Data: [['1st', '0', '0', '0'], ['2nd', '0', '0', '0'], ['3rd', '4.8', '0', '0'], ['4th', '0.2', '0', '3.0'], ['5th', '0', '0', '3.6'], ['6th', '0', '0.6', '0'], ['7th', '14.0', '0.2', '0'], ['8th', '0.4', '0', '0.2'], ['9th', '37.2', '13.0', '5.0'], ['10th', '1.0', '0.2', '0'], ['11th', '23.6', '6.8', '20.4'], ['12th', '0.2', '0.2', '7.2'], ['13th', '0', '5.0', '0.2'], ['14th', '0', '0', '0'], ['15th', '0', '22.8', '0'], ['16th', '35.6', '0.2', '0'], ['17th', '1.6', '0', '0'], ['18th', '11.0', '0', '0'], ['19th', '5.4', '0', '0'], ['20th', '0', '0'], ['21st', '0', '0'], ['22nd', '0', '4.0'], ['23rd', '0', '0'], ['24th', '0', '0'], ['25th', '0', '0'], ['26th', '0', '0'], ['27th', '0', '0'], ['28th', '7.6', '0'], ['29th', '8.2'], ['30th', '0.6'], ['31st', '1.0']]\n",
      "         date rainfall_mm\n",
      "0  2025-01-01           0\n",
      "3  2025-01-02           0\n",
      "6  2025-01-03         4.8\n",
      "9  2025-01-04         0.2\n",
      "12 2025-01-05           0\n",
      "..        ...         ...\n",
      "44 2025-03-15           0\n",
      "47 2025-03-16           0\n",
      "50 2025-03-17           0\n",
      "53 2025-03-18           0\n",
      "56 2025-03-19           0\n",
      "\n",
      "[78 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract the year (from th with scope=\"col\")\n",
    "year = soup.find('th', {'scope': 'col'}).text.strip()\n",
    "\n",
    "# Initialize the list for storing data rows\n",
    "data = []\n",
    "\n",
    "# Regular expressions pattern for checking to see if value is 1st .. 31st\n",
    "pattern = re.compile(r'^\\d{1,2}(st|nd|rd|th)$')\n",
    "\n",
    "# Iterate over each table row in the tbody\n",
    "for row in soup.find_all('tr')[1:]:  # Skip the first row (graph row)\n",
    "    row_data = []\n",
    "\n",
    "    # check row exists and is one of the data rows (1st to 31st in the first column)\n",
    "    th = row.find('th', {'scope': 'row'})\n",
    "    if th:\n",
    "        th = th.text.strip()\n",
    "        if pattern.match(th):\n",
    "            row_data.append(th)\n",
    "\n",
    "            # extract the row data\n",
    "            cells = row.find_all('td', class_='no-qc')\n",
    "            for cell in cells:\n",
    "                cell_text = cell.text.strip()\n",
    "                if cell_text: # only append non-empty cells\n",
    "                    row_data.append(cell_text)\n",
    "\n",
    "            data.append(row_data)\n",
    "\n",
    "# Print the year and the data\n",
    "print(\"Year:\", year)\n",
    "print(\"Data:\", data)\n",
    "\n",
    "# convert data to a list with dates in the format dd/mm/yy\n",
    "daily_data = []\n",
    "for i, (day, *values) in enumerate(data):\n",
    "    day_number = int(day[:-2]) # remove 'st', 'nd' etc\n",
    "    for month_number, value in enumerate(values):\n",
    "        date = datetime(int(year), month_number + 1, day_number).strftime('%d/%m/%y') # add year and format as dd/mm/yy\n",
    "        daily_data.append([date, value])\n",
    "\n",
    "# convert data to dataframe for ease of filtering etc\n",
    "df = pd.DataFrame(daily_data, columns=['date', 'rainfall_mm'])\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d/%m/%y')\n",
    "df = df.sort_values(by='date', ascending=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for script\n",
    "\n",
    "This will be placed in src and will be called from the database.py and/or data_ingestion.py so should return the data in an array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date rainfall_mm\n",
      "0  2025-01-01           0\n",
      "3  2025-01-02           0\n",
      "6  2025-01-03         4.8\n",
      "9  2025-01-04         0.2\n",
      "12 2025-01-05           0\n",
      "..        ...         ...\n",
      "44 2025-03-15           0\n",
      "47 2025-03-16           0\n",
      "50 2025-03-17           0\n",
      "53 2025-03-18           0\n",
      "56 2025-03-19           0\n",
      "\n",
      "[78 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_historical_data(soup):\n",
    "\n",
    "    # Extract the year (from th with scope=\"col\")\n",
    "    year = soup.find('th', {'scope': 'col'}).text.strip()\n",
    "\n",
    "    # Initialize the list for storing data rows\n",
    "    data = []\n",
    "\n",
    "    # Regular expressions pattern for checking to see if value is 1st .. 31st\n",
    "    pattern = re.compile(r'^\\d{1,2}(st|nd|rd|th)$')\n",
    "\n",
    "    # Iterate over each table row in the tbody\n",
    "    for row in soup.find_all('tr')[1:]:  # Skip the first row (graph row)\n",
    "        row_data = []\n",
    "\n",
    "        # check row exists and is one of the data rows (1st to 31st in the first column)\n",
    "        th = row.find('th', {'scope': 'row'})\n",
    "        if th:\n",
    "            th = th.text.strip()\n",
    "            if pattern.match(th):\n",
    "                row_data.append(th)\n",
    "\n",
    "                # extract the row data\n",
    "                cells = row.find_all('td', class_='no-qc')\n",
    "                for cell in cells:\n",
    "                    cell_text = cell.text.strip()\n",
    "                    if cell_text: # only append non-empty cells\n",
    "                        row_data.append(cell_text)\n",
    "\n",
    "                data.append(row_data)\n",
    "\n",
    "    # convert data to a list with dates in the format dd/mm/yy\n",
    "    daily_data = []\n",
    "    for i, (day, *values) in enumerate(data):\n",
    "        day_number = int(day[:-2]) # remove 'st', 'nd' etc\n",
    "        for month_number, value in enumerate(values):\n",
    "            date = datetime(int(year), month_number + 1, day_number).strftime('%d/%m/%y') # add year and format as dd/mm/yy\n",
    "            daily_data.append([date, value])\n",
    "\n",
    "    # convert data to dataframe for ease of filtering etc\n",
    "    df = pd.DataFrame(daily_data, columns=['date', 'rainfall_mm'])\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d/%m/%y')\n",
    "    df = df.sort_values(by='date', ascending=True)\n",
    "    return df\n",
    "\n",
    "df = extract_historical_data(soup=soup)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder in case we need to use pickle to save some test data for the database notebook to play with\n",
    "# will try and set up import and use / test the src version in the first instance\n",
    "if False:\n",
    "        \n",
    "    import pickle\n",
    "\n",
    "    # save file for database.ipynb to play with\n",
    "    with open('data/df_forecast.pkl', 'wb') as f:\n",
    "        pickle.dump(df_forecast, f)\n",
    "\n",
    "    # Load DataFrame from pickle file\n",
    "    with open('df_forecast.pkl', 'rb') as f:\n",
    "        loaded_df = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "happy_plants",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
